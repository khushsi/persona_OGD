{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipy_table\n",
    "!pip install plotly\n",
    "!pip install yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for basic mathematics operation \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import plotting\n",
    "\n",
    "# for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "from pandas import json_normalize\n",
    "import math\n",
    "\n",
    "# for interactive visualizations\n",
    "import plotly.offline as py\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "init_notebook_mode(connected = True)\n",
    "import plotly.figure_factory as ff\n",
    "py.init_notebook_mode()\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# for path\n",
    "import os\n",
    "import copy\n",
    "datafile = '../PGDnophilly_1_old.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = pd.read_csv(datafile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Header Files for Data preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Header Files for finding optimal linkage for clustering\n",
    "from scipy.cluster.hierarchy import cophenet\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# Header files for visualizing the clusters\n",
    "from scipy.cluster.hierarchy import linkage,dendrogram,cut_tree\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "# Header Files for Agglomerative Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Header Files for KMeans Custering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Header files for dimensionality Reduction\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "# Header files for DBSCan\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "sns.set(rc={'figure.figsize':(11,8)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(datafile)\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')] \n",
    "df.head()\n",
    "df=df.fillna('')\n",
    "df = df.rename(columns={'u000id':'userID'})\n",
    "df =df[['userID','action','types of posts','Challenges','Proficiency in DK','Proficiency in CS']]\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')] \n",
    "    \n",
    "challenges=[\n",
    "'ASS',\n",
    "'D-D',\n",
    "'D-U',\n",
    "'FIND',\n",
    "# 'SCHE',\n",
    "# 'SHARE',\n",
    "'U-D',\n",
    "'U-U',\n",
    "'UNS', \n",
    "]\n",
    "\n",
    "types_of_posts=[\n",
    "'A-A',\n",
    "'A-CONFI',\n",
    "'COUR',\n",
    "# 'FUA',\n",
    "'Q-CLAR',\n",
    "# 'Q-CONF',\n",
    "#'Q-INT',\n",
    "# 'Q-PUSH',\n",
    "#'A-ADD',\n",
    "#'A-CONFA',   \n",
    "# 'OTHER',\n",
    "#'Q-ADD', \n",
    "#'A-RA',    \n",
    "'Q-Q',\n",
    "'REPORT',\n",
    "'REQUEST',  \n",
    "]\n",
    "\n",
    "renametypes={'Q-ADD':'Q-Q','Q-INT':'Q-Q','A-ADD':'A-A',\n",
    "             'A-RA':'A-A','A-CONFA':'A-CONFI',\n",
    "            'Q-CONF' : 'Q-Q', 'Q-PUSH' : 'Q-Q','FUA':'Q-Q'}\n",
    "\n",
    "def renamerow(x):\n",
    "    in_x=x\n",
    "    for key in renametypes:\n",
    "        x=x.replace(key+\"@\",renametypes[key]+\"@\")\n",
    "    return x\n",
    "        \n",
    "\n",
    "df=df[['userID','Challenges','types of posts','Proficiency in DK','Proficiency in CS']]\n",
    "df = df[~ (df['userID'].isin(['u00002','u00006','u00007']))]\n",
    "print(\"total number of records\",len(df))\n",
    "print(\"No of users\",len(df['userID'].unique()))\n",
    "df['Challenges']=df['Challenges'].apply(lambda x : '@'.join(x.replace(\",\",\"\").split())+\"@\")\n",
    "df['types_of_posts']=df['types of posts'].apply(lambda x : '@'.join(x.replace(\",\",\"\").split())+\"@\")\n",
    "df['types_of_posts']=df['types_of_posts'].apply(lambda x : renamerow(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pers=df.groupby(['userID'],as_index=False).agg( {'userID':'max'})    \n",
    "for index,row in df_pers.iterrows():\n",
    "    for types in list(challenges):\n",
    "        types=types+\"@\"\n",
    "        if len(df[ (df['userID'] == row['userID']) & df['Challenges'].str.contains(types)]) > 0:\n",
    "            df_pers.loc[index,'Challenges_'+types]= 1\n",
    "        else:\n",
    "            df_pers.loc[index,'Challenges_'+types]= 0\n",
    "\n",
    "    for types in list(types_of_posts):\n",
    "        types=types+\"@\"\n",
    "        df_pers.loc[index,'types_of_posts_'+types]=len(df[ (df['userID'] == row['userID']) & df['types_of_posts'].str.contains(types)])/len(df[ (df['userID'] == row['userID'])])\n",
    "    temp=df[ (df['userID'] == row['userID']) &  ( df['Proficiency in CS'] != '' )]['Proficiency in CS'].unique()\n",
    "    val = 1\n",
    "    if len(temp) > 0:\n",
    "        val = max(temp)\n",
    "        if val == 4 or val == 5:\n",
    "            val = 5\n",
    "        if val == 1 or val == 2:\n",
    "            val = 1\n",
    "    else:\n",
    "        print(\"no proficiency\")\n",
    "    df_pers.loc[index,'tProficiency in CS_'+str(int(val))]= 1\n",
    "\n",
    "    temp=df[ (df['userID'] == row['userID']) &  ( df['Proficiency in DK'] != '' )]['Proficiency in DK'].unique()\n",
    "    val = 1\n",
    "    if len(temp) > 0:\n",
    "        val = max(temp)\n",
    "        if val == 4 or val == 5:\n",
    "            val = 5\n",
    "        if val == 1 or val == 2:\n",
    "            val = 1\n",
    "    else:\n",
    "        print(\"no proficiency dk\")\n",
    "        \n",
    "    df_pers.loc[index,'tProficiency in DK_'+str(int(val))]= 1\n",
    "        \n",
    "df_pers.head(20)\n",
    "print(renametypes.keys())\n",
    "print(df_pers.columns)\n",
    "df_pers = df_pers.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pers['tProficiency in DK_3'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# %matplotlib notebook\n",
    "df_clus = df_pers.drop(columns=['userID'])\n",
    "normalized_vectors = preprocessing.normalize(df_clus)\n",
    "\n",
    "i=3\n",
    "plt.title(\"Principal Component Analysis of Philly User Dataset\",fontsize=20)\n",
    "normalized_kmeans = KMeans(n_clusters=i).fit(normalized_vectors)\n",
    "print(i,'Cosine kmeans:{}'.format(silhouette_score(normalized_vectors,\n",
    "                                          normalized_kmeans.labels_,\n",
    "                                          metric='cosine')))\n",
    "df_clus['cluster']=normalized_kmeans.labels_\n",
    "\n",
    "targets = list(df_clus['cluster'])\n",
    "# print(targets)\n",
    "ranking = np.random.normal(size=len(df_clus))\n",
    "\n",
    "X_scaled = normalized_vectors\n",
    "y = targets\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "pca.fit(X_scaled) \n",
    "X_pca = pca.transform(X_scaled) \n",
    "\n",
    "ex_variance=np.var(X_pca,axis=0)\n",
    "ex_variance_ratio = ex_variance/np.sum(ex_variance)\n",
    "ex_variance_ratio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xax = X_pca[:,0]\n",
    "Yax = X_pca[:,1]\n",
    "Zax = X_pca[:,2]\n",
    "print(len(df_clus[df_clus['cluster'] ==0]))\n",
    "# print(Xax)\n",
    "cdict = {0:'red',1:'green',2:'blue'}\n",
    "labl = {0:'General',1:'Strategist',2:'Recruits'}\n",
    "marker = {0:'*',1:'*',2:'*'}\n",
    "alpha = {0:.3, 1:.3,2:.33}\n",
    "center_pca = pca.transform(normalized_kmeans.cluster_centers_) \n",
    "\n",
    "print(center_pca)\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "fig.patch.set_facecolor('white')\n",
    "for l in np.unique(y):\n",
    "    ix=np.where(np.asarray(y)==l)\n",
    "    ax.scatter(Xax[ix], Yax[ix], Zax[ix], c=cdict[l], s=50,\n",
    "           label=labl[l], marker=marker[l], alpha=alpha[l])\n",
    "# print(X_pca[:,0])\n",
    "# print(\"hi\")\n",
    "for l in range(3):\n",
    "    ax.scatter(center_pca[:,0][l],center_pca[:,1][l], center_pca[:,2][l],c=l,marker='o',s=50)\n",
    "\n",
    "    # for loop ends\n",
    "ax.set_xlabel(\"First\", fontsize=8)\n",
    "ax.set_ylabel(\"Second \", fontsize=8)\n",
    "ax.set_zlabel(\"Third \", fontsize=8)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (HelPer)",
   "language": "python",
   "name": "pycharm-424e0288"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
